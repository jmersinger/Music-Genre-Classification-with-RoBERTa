{"cells":[{"cell_type":"code","execution_count":null,"id":"fWk6puvn-C5-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12299,"status":"ok","timestamp":1734008065802,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"fWk6puvn-C5-","outputId":"a970a3c7-7270-4459-89dd-affba2e832c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"BfB_vBYP-6UC","metadata":{"id":"BfB_vBYP-6UC"},"outputs":[],"source":["import pandas as pd\n","import kagglehub\n","\n","# Download data and create genre column for tracks using artists\n","def download_and_clean():\n","\n","    path = kagglehub.dataset_download(\"yamaerenay/spotify-dataset-19212020-600k-tracks\")\n","    artists_path = path + '/artists.csv'\n","    tracks_path = path + '/tracks.csv'\n","\n","    artists_df = pd.read_csv(artists_path)\n","    tracks_df = pd.read_csv(tracks_path)\n","\n","    artists_df = artists_df.dropna().drop_duplicates()\n","    tracks_df = tracks_df.dropna().drop_duplicates()\n","\n","    artists_df = artists_df[artists_df['genres'].apply(lambda x: len(eval(x)) > 0 if isinstance(x, str) else False)]\n","\n","    valid_artists = set(artists_df['name'])\n","    tracks_df = tracks_df[tracks_df['artists'].apply(lambda x: all(artist in valid_artists for artist in eval(x)) if isinstance(x, str) else False)]\n","\n","    artist_to_genres = dict(zip(artists_df['name'], artists_df['genres']))\n","\n","    def get_genres_for_track(artists_list):\n","        if isinstance(artists_list, str):\n","            try:\n","                artists_list = eval(artists_list)\n","                genres = [genre for artist in artists_list if artist in artist_to_genres for genre in eval(artist_to_genres[artist])]\n","                return list(set(genres))\n","            except:\n","                return []\n","        return []\n","\n","    tracks_df['genres'] = tracks_df['artists'].apply(get_genres_for_track)\n","\n","    artists_df.to_csv('/content/drive/MyDrive/nlp-proj/data/cleaned_data/cleaned_artists.csv', index=False)\n","    tracks_df.to_csv('/content/drive/MyDrive/nlp-proj/data/cleaned_data/cleaned_tracks.csv', index=False)\n","\n","    return artists_df, tracks_df\n"]},{"cell_type":"code","execution_count":null,"id":"175073ea-4071-4aaf-a332-e354846b474c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46153,"status":"ok","timestamp":1734008112608,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"175073ea-4071-4aaf-a332-e354846b474c","outputId":"92d83e18-037c-4b50-80b1-123455e56bef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/yamaerenay/spotify-dataset-19212020-600k-tracks?dataset_version_number=1...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 193M/193M [00:01<00:00, 178MB/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting files...\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# from data.cleaning import download_and_clean\n","\n","artists, tracks = download_and_clean()"]},{"cell_type":"code","execution_count":null,"id":"d54a8e77-2193-4fe4-8043-282cc51d056f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134,"status":"ok","timestamp":1734008112740,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"d54a8e77-2193-4fe4-8043-282cc51d056f","outputId":"0b798aeb-26cd-4267-d804-a7b493c17e30"},"outputs":[{"name":"stdout","output_type":"stream","text":["                         id  followers                      genres  \\\n","45   0VLMVnVbJyJ4oyZs2L3Yl2       71.0          ['carnaval cadiz']   \n","46   0dt23bs4w8zx154C5xdVyl       63.0          ['carnaval cadiz']   \n","47   0pGhoB99qpEJEsBQxgaskQ       64.0          ['carnaval cadiz']   \n","48   3HDrX2OtSuXLW5dLR85uN3       53.0          ['carnaval cadiz']   \n","136  22mLrN5fkppmuUPsHx6i2G       59.0  ['classical harp', 'harp']   \n","\n","                             name  popularity  \n","45   Las Viudas De Los Bisabuelos           6  \n","46              Los De Capuchinos           5  \n","47             Los “Pofesionales”           7  \n","48      Los Que No Paran De Rajar           6  \n","136                   Vera Dulova           3  \n"]}],"source":["print(artists.head())"]},{"cell_type":"code","execution_count":null,"id":"07ae631a-3033-429d-8484-1f0d06c826a7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1734008112740,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"07ae631a-3033-429d-8484-1f0d06c826a7","outputId":"6d574aab-6d95-434e-cbf4-e39e45d01d43"},"outputs":[{"name":"stdout","output_type":"stream","text":["                       id                                name  popularity  \\\n","2  07A5yehtSnoedViJAZkNnc  Vivo para Quererte - Remasterizado           0   \n","3  08FmqUhxtyLTn6pAh6bk45       El Prisionero - Remasterizado           0   \n","4  08y9GfoqCWfOGsKdwojr5e                 Lady of the Evening           0   \n","5  0BRXJHRNGQ3W4v9frnSfhu                           Ave Maria           0   \n","7  0IA0Hju8CAgYfV1hwhidBH                             La Java           0   \n","\n","   duration_ms  explicit              artists                  id_artists  \\\n","2       181640         0  ['Ignacio Corsini']  ['5LiOoJbxVSAMkBS2fUm3X2']   \n","3       176907         0  ['Ignacio Corsini']  ['5LiOoJbxVSAMkBS2fUm3X2']   \n","4       163080         0      ['Dick Haymes']  ['3BiJGZsyX9sJchTqcSA7Su']   \n","5       178933         0      ['Dick Haymes']  ['3BiJGZsyX9sJchTqcSA7Su']   \n","7       161427         0      ['Mistinguett']  ['4AxgXfD7ISvJSTObqm4aIE']   \n","\n","  release_date  danceability  energy  ...  loudness  mode  speechiness  \\\n","2   1922-03-21         0.434  0.1770  ...   -21.180     1       0.0512   \n","3   1922-03-21         0.321  0.0946  ...   -27.961     1       0.0504   \n","4         1922         0.402  0.1580  ...   -16.900     0       0.0390   \n","5         1922         0.227  0.2610  ...   -12.343     1       0.0382   \n","7         1922         0.563  0.1840  ...   -13.757     1       0.0512   \n","\n","   acousticness  instrumentalness  liveness  valence    tempo  time_signature  \\\n","2         0.994          0.021800    0.2120   0.4570  130.418               5   \n","3         0.995          0.918000    0.1040   0.3970  169.980               3   \n","4         0.989          0.130000    0.3110   0.1960  103.220               4   \n","5         0.994          0.247000    0.0977   0.0539  118.891               4   \n","7         0.993          0.000016    0.3250   0.6540  133.088               3   \n","\n","                                              genres  \n","2                             [tango, vintage tango]  \n","3                             [tango, vintage tango]  \n","4  [swing, lounge, big band, easy listening, adul...  \n","5  [swing, lounge, big band, easy listening, adul...  \n","7                                  [vintage chanson]  \n","\n","[5 rows x 21 columns]\n"]}],"source":["print(tracks.head())"]},{"cell_type":"code","execution_count":null,"id":"9364f6fa-96a5-40dd-8d47-2a78482f8567","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1734008112862,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"9364f6fa-96a5-40dd-8d47-2a78482f8567","outputId":"14c335af-cfaa-44b1-ed60-3e5ac664366c"},"outputs":[{"data":{"text/plain":["4706"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# The next few cells create a multi-hot vector for storing the genre labels for modeling\n","\n","from itertools import chain\n","all_genres = set(chain.from_iterable(tracks[\"genres\"]))\n","len(all_genres)\n","# all_genres"]},{"cell_type":"code","execution_count":null,"id":"af999b92-4010-4fb9-b5da-6f6cc67380a1","metadata":{"id":"af999b92-4010-4fb9-b5da-6f6cc67380a1"},"outputs":[],"source":["genre_to_index = {genre: idx for idx, genre in enumerate(sorted(all_genres))}\n","# genre_to_index"]},{"cell_type":"code","execution_count":null,"id":"2f8f25fb-1407-42a6-9989-c04e25dd56c1","metadata":{"id":"2f8f25fb-1407-42a6-9989-c04e25dd56c1"},"outputs":[],"source":["def multihot_vector(genres, index_dict):\n","    multihot = [0] * len(index_dict)\n","    for genre in genres:\n","        multihot[index_dict[genre]] = 1\n","    return multihot"]},{"cell_type":"code","execution_count":null,"id":"428fca29-7f55-4b3e-9537-e2ef8afb9573","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"executionInfo":{"elapsed":33888,"status":"ok","timestamp":1734008146747,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"428fca29-7f55-4b3e-9537-e2ef8afb9573","outputId":"7951457b-95f6-42c8-dd7c-b200dc46e6a0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>multi_hot_genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>586667</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>586668</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>586669</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>586670</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>586671</th>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>499064 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> object</label>"],"text/plain":["2         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","3         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","4         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","5         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","7         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","                                ...                        \n","586667    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","586668    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","586669    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","586670    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","586671    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","Name: multi_hot_genres, Length: 499064, dtype: object"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tracks[\"multi_hot_genres\"] = tracks[\"genres\"].apply(\n","    lambda genres: multihot_vector(genres, genre_to_index)\n",")\n","tracks[\"multi_hot_genres\"]"]},{"cell_type":"code","execution_count":null,"id":"4d5aedaf-66d2-4faf-aa2e-bbe8c2504aec","metadata":{"id":"4d5aedaf-66d2-4faf-aa2e-bbe8c2504aec"},"outputs":[],"source":["# Split the data into 80-10-10\n","\n","from sklearn.model_selection import train_test_split\n","\n","X = tracks[[\"name\", \"popularity\", \"duration_ms\", \"explicit\", \"release_date\", \"energy\", \"danceability\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"valence\", \"tempo\", \"time_signature\"]]\n","y = tracks[\"multi_hot_genres\"].tolist()\n","\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=478)\n","X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=478)"]},{"cell_type":"code","execution_count":null,"id":"34f732a6-c0f2-4d27-b749-2fa9ebef55b7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1734012162583,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"34f732a6-c0f2-4d27-b749-2fa9ebef55b7","outputId":"4d05c9b3-a214-400b-bdab-877f8fcddce1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set size: 399251\n","Dev set size: 49906\n","Test set size: 49907\n"]}],"source":["print(f\"Train set size: {len(X_train)}\")\n","print(f\"Dev set size: {len(X_dev)}\")\n","print(f\"Test set size: {len(X_test)}\")"]},{"cell_type":"code","execution_count":null,"id":"cc59b6ea-b98e-42d5-8a6c-91991e03982c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223498,"status":"ok","timestamp":1734012386079,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"cc59b6ea-b98e-42d5-8a6c-91991e03982c","outputId":"a3c04dd6-9de8-4eb1-9673-213e80280409"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original number of labels: 4706\n","Filtered number of labels: 1529\n"]}],"source":["# Drop genres that have less than 100 occurences\n","\n","\n","label_counts = np.sum(y_train, axis=0)\n","\n","threshold =100\n","selected_labels = np.where(label_counts >= threshold)[0]\n","\n","def filter_labels(y, selected_labels):\n","    return np.array([[y_sample[i] for i in selected_labels] for y_sample in y])\n","\n","y_train = filter_labels(y_train, selected_labels)\n","y_dev = filter_labels(y_dev, selected_labels)\n","y_test = filter_labels(y_test, selected_labels)\n","\n","filtered_genre_to_index = {genre: idx for idx, genre in enumerate(selected_labels)}\n","index_to_genre = {v: k for k, v in filtered_genre_to_index.items()}\n","\n","print(f\"Original number of labels: {len(label_counts)}\")\n","print(f\"Filtered number of labels: {len(selected_labels)}\")\n"]},{"cell_type":"code","execution_count":null,"id":"b9aa7530-f23d-4471-ac80-0e9c56d18d66","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4393,"status":"ok","timestamp":1734012390470,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"b9aa7530-f23d-4471-ac80-0e9c56d18d66","outputId":"7ede6241-d44f-4097-86b7-8cd0f0ea004d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set size after filtering: 386974\n","Dev set size after filtering: 48297\n","Test set size after filtering: 48376\n"]}],"source":["# Drop rows with no positive labels\n","def remove_empty_labels(X, y):\n","    non_empty_indices = [i for i, labels in enumerate(y) if np.sum(labels) > 0]\n","    X_filtered = X.iloc[non_empty_indices].reset_index(drop=True)\n","    y_filtered = np.array([y[i] for i in non_empty_indices])\n","    return X_filtered, y_filtered\n","\n","X_train, y_train = remove_empty_labels(X_train, y_train)\n","X_dev, y_dev = remove_empty_labels(X_dev, y_dev)\n","X_test, y_test = remove_empty_labels(X_test, y_test)\n","\n","print(f\"Train set size after filtering: {len(X_train)}\")\n","print(f\"Dev set size after filtering: {len(X_dev)}\")\n","print(f\"Test set size after filtering: {len(X_test)}\")"]},{"cell_type":"code","execution_count":null,"id":"FIj0vn2pBb3z","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2290,"status":"ok","timestamp":1734012392755,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"FIj0vn2pBb3z","outputId":"406d5375-0319-4b78-f1a8-6cb4751f7d14"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"]}],"source":["!pip install numpy"]},{"cell_type":"code","execution_count":null,"id":"6f8a9644-ecff-49a1-a508-e5519cc64df0","metadata":{"id":"6f8a9644-ecff-49a1-a508-e5519cc64df0"},"outputs":[],"source":["from transformers import RobertaModel, RobertaTokenizer\n","import torch\n","import torch.nn as nn\n","from transformers import TrainingArguments, Trainer\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, jaccard_score, hamming_loss\n","import numpy as np\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"]},{"cell_type":"code","execution_count":null,"id":"g3tbqyFpHTaW","metadata":{"id":"g3tbqyFpHTaW"},"outputs":[],"source":["# Tokenizing and preparing the feature for modeling\n","def tokenize_data(X):\n","    combined_text = X.apply(lambda row: \" \".join(row.astype(str)), axis=1)\n","\n","    return tokenizer(\n","        combined_text.tolist(),\n","        padding=True,\n","        truncation=True,\n","        max_length=128,\n","        return_tensors=\"pt\"\n","    )\n","\n","# Dataset preparation\n","class MultiLabelDataset(torch.utils.data.Dataset):\n","    def __init__(self, X, y):\n","        tokenized = tokenize_data(X)\n","\n","        self.input_ids = tokenized[\"input_ids\"]\n","        self.attention_mask = tokenized[\"attention_mask\"]\n","        self.labels = torch.tensor(y)\n","\n","        token_lengths = [len(ids) for ids in self.input_ids]\n","        print(f\"Token length range: {min(token_lengths)} to {max(token_lengths)}\")\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"input_ids\": self.input_ids[idx],\n","            \"attention_mask\": self.attention_mask[idx],\n","            \"labels\": self.labels[idx]\n","        }"]},{"cell_type":"code","execution_count":null,"id":"E43VKZsBHVat","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200687,"status":"ok","timestamp":1734012593666,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"E43VKZsBHVat","outputId":"200f6bf4-6598-418e-f86d-4012a4c37bbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Token length range: 128 to 128\n","Token length range: 128 to 128\n","Token length range: 128 to 128\n"]}],"source":["train_dataset = MultiLabelDataset(X_train, y_train)\n","dev_dataset = MultiLabelDataset(X_dev, y_dev)\n","test_dataset = MultiLabelDataset(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"id":"b6f708e1-5d64-4f86-beca-030d73f16309","metadata":{"id":"b6f708e1-5d64-4f86-beca-030d73f16309"},"outputs":[],"source":["# RoBERTa, following similar to the model described in “Punk or Funk: Understanding the Performance of RoBERTa on Music Genre Classification.”\n","class MultiLabelRoBERTa(nn.Module):\n","    def __init__(self, num_labels):\n","        super(MultiLabelRoBERTa, self).__init__()\n","        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.roberta.config.hidden_size, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, num_labels)\n","        )\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        logits = self.classifier(outputs.pooler_output)\n","\n","        loss = None\n","        if labels is not None:\n","            criterion = nn.BCEWithLogitsLoss()\n","            loss = criterion(logits, labels.float())\n","\n","        return {\"loss\": loss, \"logits\": logits}\n","\n","# Metrics\n","def compute_metrics(pred, threshold_range=(0.05, 0.55, 0.05), prob=True):\n","    logits, labels = pred\n","    output = logits\n","    if prob:\n","        output = torch.sigmoid(torch.tensor(logits))\n","\n","    # Find probability range\n","    prob_min = output.min().item()\n","    prob_max = output.max().item()\n","    prob_mean = output.mean().item()\n","\n","    def prob_threshold_pred(output, threshold):\n","        if isinstance(output, np.ndarray):\n","            return (output > threshold).astype(int)\n","        return (output > threshold).int()\n","\n","    def calc_metrics(labels, predictions):\n","        subset_accuracy = accuracy_score(labels, predictions)\n","        precision = precision_score(labels, predictions, average=\"micro\")\n","        recall = recall_score(labels, predictions, average=\"micro\")\n","        f1 = f1_score(labels, predictions, average=\"micro\")\n","        jaccard = jaccard_score(labels, predictions, average='samples')\n","        hamming = hamming_loss(labels, predictions)\n","\n","        return subset_accuracy, precision, recall, f1, jaccard, hamming\n","\n","    threshold_results = {}\n","    for threshold in np.arange(*threshold_range):\n","        predictions = prob_threshold_pred(output, threshold)\n","        subset_accuracy, precision, recall, f1, jaccard, hamming = calc_metrics(labels, predictions)\n","        threshold_results[threshold] = {\n","            \"accuracy\": subset_accuracy,\n","            \"precision\": precision,\n","            \"recall\": recall,\n","            \"f1\": f1,\n","            \"hamming\": hamming,\n","            \"jaccard\": jaccard\n","        }\n","\n","    # Find optimal probability threshold\n","    optimal_threshold = max(threshold_results, key=lambda t: threshold_results[t][\"f1\"])\n","    optimal_threshold_metrics = threshold_results[optimal_threshold]\n","\n","    return {\n","        \"prob_min\": prob_min,\n","        \"prob_max\": prob_max,\n","        \"prob_mean\": prob_mean,\n","        \"optimal_threshold\": optimal_threshold,\n","        \"optimal_threshold_accuracy\": optimal_threshold_metrics[\"accuracy\"],\n","        \"optimal_threshold_precision\": optimal_threshold_metrics[\"precision\"],\n","        \"optimal_threshold_recall\": optimal_threshold_metrics[\"recall\"],\n","        \"optimal_threshold_f1\": optimal_threshold_metrics[\"f1\"],\n","        \"optimal_threshold_hamming\": optimal_threshold_metrics[\"hamming\"],\n","        \"optimal_threshold_jaccard\": optimal_threshold_metrics[\"jaccard\"],\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"c667123f-dd36-4247-a228-36607069bf75","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1734012593857,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"c667123f-dd36-4247-a228-36607069bf75","outputId":"95d9b38a-d6ca-4e81-874e-7841333dbb0b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Initialize the model\n","def initialize_model():\n","    num_labels = len(y_train[0])\n","    model = MultiLabelRoBERTa(num_labels=num_labels)\n","    model.roberta.gradient_checkpointing_enable()\n","    return model\n","model = initialize_model()"]},{"cell_type":"code","execution_count":null,"id":"075be418-828e-4c62-bb1a-f5bf0c8c7d9e","metadata":{"id":"075be418-828e-4c62-bb1a-f5bf0c8c7d9e"},"outputs":[],"source":["# Training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    eval_strategy=\"no\",\n","    save_strategy=\"no\",\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=32,\n","    # gradient_accumulation_steps=2,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    fp16=True\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"53111b9e-98ac-42ef-875b-187ddcf9e8ca","metadata":{"id":"53111b9e-98ac-42ef-875b-187ddcf9e8ca"},"outputs":[],"source":["# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=dev_dataset,\n","    processing_class=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"id":"c5a70068-67c3-4ef7-a078-4f4977fb1bfd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":9964761,"status":"ok","timestamp":1734022558868,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"c5a70068-67c3-4ef7-a078-4f4977fb1bfd","outputId":"0c204849-0087-4c42-aaf3-0c9259277e14"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='120930' max='120930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [120930/120930 2:45:55, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.527300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.187000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.067800</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.039500</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.031100</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.027000</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.024500</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.022900</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.021500</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.020500</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.019600</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.018800</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.018300</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.017700</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.017100</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.016400</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.016100</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.015900</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.015400</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.015100</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.015000</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.014700</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.014400</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.014100</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.013900</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.013800</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.013500</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.013500</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.013300</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.013200</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.012900</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.012900</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.012900</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.012700</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.012500</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.012300</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.012300</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.012300</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>0.012300</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>0.012000</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>0.012100</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>0.012000</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>0.011800</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>0.011800</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>0.011700</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>0.011600</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>0.011500</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>0.011400</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>0.011300</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>0.011100</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>0.011000</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>0.011100</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>0.011100</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>0.010900</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>0.010800</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>0.010800</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>0.010800</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>0.010600</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>0.010600</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>0.010500</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>0.010600</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>0.010600</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>0.010500</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>0.010400</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>0.010400</td>\n","    </tr>\n","    <tr>\n","      <td>34500</td>\n","      <td>0.010300</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>0.010200</td>\n","    </tr>\n","    <tr>\n","      <td>35500</td>\n","      <td>0.010300</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>0.010300</td>\n","    </tr>\n","    <tr>\n","      <td>36500</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <td>37500</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <td>38500</td>\n","      <td>0.009900</td>\n","    </tr>\n","    <tr>\n","      <td>39000</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <td>39500</td>\n","      <td>0.009800</td>\n","    </tr>\n","    <tr>\n","      <td>40000</td>\n","      <td>0.009800</td>\n","    </tr>\n","    <tr>\n","      <td>40500</td>\n","      <td>0.009800</td>\n","    </tr>\n","    <tr>\n","      <td>41000</td>\n","      <td>0.009800</td>\n","    </tr>\n","    <tr>\n","      <td>41500</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>42000</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>42500</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>43000</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>43500</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>44000</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>44500</td>\n","      <td>0.009700</td>\n","    </tr>\n","    <tr>\n","      <td>45000</td>\n","      <td>0.009600</td>\n","    </tr>\n","    <tr>\n","      <td>45500</td>\n","      <td>0.009500</td>\n","    </tr>\n","    <tr>\n","      <td>46000</td>\n","      <td>0.009500</td>\n","    </tr>\n","    <tr>\n","      <td>46500</td>\n","      <td>0.009500</td>\n","    </tr>\n","    <tr>\n","      <td>47000</td>\n","      <td>0.009500</td>\n","    </tr>\n","    <tr>\n","      <td>47500</td>\n","      <td>0.009400</td>\n","    </tr>\n","    <tr>\n","      <td>48000</td>\n","      <td>0.009400</td>\n","    </tr>\n","    <tr>\n","      <td>48500</td>\n","      <td>0.009300</td>\n","    </tr>\n","    <tr>\n","      <td>49000</td>\n","      <td>0.009200</td>\n","    </tr>\n","    <tr>\n","      <td>49500</td>\n","      <td>0.009300</td>\n","    </tr>\n","    <tr>\n","      <td>50000</td>\n","      <td>0.009200</td>\n","    </tr>\n","    <tr>\n","      <td>50500</td>\n","      <td>0.009200</td>\n","    </tr>\n","    <tr>\n","      <td>51000</td>\n","      <td>0.009300</td>\n","    </tr>\n","    <tr>\n","      <td>51500</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>52000</td>\n","      <td>0.009200</td>\n","    </tr>\n","    <tr>\n","      <td>52500</td>\n","      <td>0.009200</td>\n","    </tr>\n","    <tr>\n","      <td>53000</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>53500</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>54000</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>54500</td>\n","      <td>0.009000</td>\n","    </tr>\n","    <tr>\n","      <td>55000</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>55500</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>56000</td>\n","      <td>0.009000</td>\n","    </tr>\n","    <tr>\n","      <td>56500</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>57000</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>57500</td>\n","      <td>0.009000</td>\n","    </tr>\n","    <tr>\n","      <td>58000</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>58500</td>\n","      <td>0.009000</td>\n","    </tr>\n","    <tr>\n","      <td>59000</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>59500</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>60000</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>60500</td>\n","      <td>0.009000</td>\n","    </tr>\n","    <tr>\n","      <td>61000</td>\n","      <td>0.008800</td>\n","    </tr>\n","    <tr>\n","      <td>61500</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>62000</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>62500</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>63000</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>63500</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>64000</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>64500</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>65000</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>65500</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>66000</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>66500</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>67000</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>67500</td>\n","      <td>0.008700</td>\n","    </tr>\n","    <tr>\n","      <td>68000</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>68500</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>69000</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>69500</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>70000</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>70500</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>71000</td>\n","      <td>0.008500</td>\n","    </tr>\n","    <tr>\n","      <td>71500</td>\n","      <td>0.008500</td>\n","    </tr>\n","    <tr>\n","      <td>72000</td>\n","      <td>0.008600</td>\n","    </tr>\n","    <tr>\n","      <td>72500</td>\n","      <td>0.008500</td>\n","    </tr>\n","    <tr>\n","      <td>73000</td>\n","      <td>0.008500</td>\n","    </tr>\n","    <tr>\n","      <td>73500</td>\n","      <td>0.008400</td>\n","    </tr>\n","    <tr>\n","      <td>74000</td>\n","      <td>0.008500</td>\n","    </tr>\n","    <tr>\n","      <td>74500</td>\n","      <td>0.008400</td>\n","    </tr>\n","    <tr>\n","      <td>75000</td>\n","      <td>0.008500</td>\n","    </tr>\n","    <tr>\n","      <td>75500</td>\n","      <td>0.008400</td>\n","    </tr>\n","    <tr>\n","      <td>76000</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>76500</td>\n","      <td>0.008400</td>\n","    </tr>\n","    <tr>\n","      <td>77000</td>\n","      <td>0.008400</td>\n","    </tr>\n","    <tr>\n","      <td>77500</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>78000</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>78500</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>79000</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>79500</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>80000</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>80500</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>81000</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>81500</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>82000</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>82500</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>83000</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>83500</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>84000</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>84500</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>85000</td>\n","      <td>0.008300</td>\n","    </tr>\n","    <tr>\n","      <td>85500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>86000</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>86500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>87000</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>87500</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>88000</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>88500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>89000</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>89500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>90000</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>90500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>91000</td>\n","      <td>0.008200</td>\n","    </tr>\n","    <tr>\n","      <td>91500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>92000</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>92500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>93000</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>93500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>94000</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>94500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>95000</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>95500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>96000</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>96500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>97000</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>97500</td>\n","      <td>0.008100</td>\n","    </tr>\n","    <tr>\n","      <td>98000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>98500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>99000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>99500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>100000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>100500</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>101000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>101500</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>102000</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>102500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>103000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>103500</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>104000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>104500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>105000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>105500</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>106000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>106500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>107000</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>107500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>108000</td>\n","      <td>0.008000</td>\n","    </tr>\n","    <tr>\n","      <td>108500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>109000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>109500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>110000</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>110500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>111000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>111500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>112000</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>112500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>113000</td>\n","      <td>0.007700</td>\n","    </tr>\n","    <tr>\n","      <td>113500</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>114000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>114500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>115000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>115500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>116000</td>\n","      <td>0.007700</td>\n","    </tr>\n","    <tr>\n","      <td>116500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>117000</td>\n","      <td>0.007900</td>\n","    </tr>\n","    <tr>\n","      <td>117500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>118000</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>118500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>119000</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>119500</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>120000</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>120500</td>\n","      <td>0.007900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=120930, training_loss=0.01324376447378411, metrics={'train_runtime': 9955.9934, 'train_samples_per_second': 388.684, 'train_steps_per_second': 12.146, 'total_flos': 0.0, 'train_loss': 0.01324376447378411, 'epoch': 10.0})"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model\n","#NO Liveness\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"f0a4f66a-b07c-46c7-bba8-f26d88542aab","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":1020280,"status":"ok","timestamp":1734023579144,"user":{"displayName":"Jude Mersinger","userId":"04053644871073057878"},"user_tz":300},"id":"f0a4f66a-b07c-46c7-bba8-f26d88542aab","outputId":"e2ef297a-4604-4920-c44e-e010acaccc96"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3024' max='3024' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3024/3024 01:04]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.007541674189269543, 'eval_prob_min': 1.9923529514555283e-14, 'eval_prob_max': 0.9971439242362976, 'eval_prob_mean': 0.0020563765428960323, 'eval_optimal_threshold': 0.2, 'eval_optimal_threshold_accuracy': 0.08549694063171821, 'eval_optimal_threshold_precision': 0.4941827602449364, 'eval_optimal_threshold_recall': 0.4583067136265596, 'eval_optimal_threshold_f1': 0.4755690912954175, 'eval_optimal_threshold_hamming': 0.002502619279563195, 'eval_optimal_threshold_jaccard': 0.32229010580074324, 'eval_runtime': 1020.1924, 'eval_samples_per_second': 47.419, 'eval_steps_per_second': 2.964, 'epoch': 10.0}\n"]}],"source":["# Evaluate on the test set\n","metrics = trainer.evaluate(test_dataset)\n","print(metrics)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}